									**VisTracing in One Weekend**
					Inspired by [Ray Tracing in One Weekend](https://raytracing.github.io/books/RayTracingInOneWeekend.html) by [Peter Shirley](https://github.com/petershirley)
					Using illustrations from [Scratchapixel](https://www.scratchapixel.com/)

Introduction
============
Many people have written ray tracers in Garry's Mod, but few have explored the more serious side of light transport, reserving themselves to basic lighting models and guesswork. With VisTracing in One Weekend I hope to provide a gateway into the wider field of light transport, while remaining in GMod and assuming only a minimal understanding of ray tracing.  

If you're entirely unfamiliar with ray tracing, specifically ray tracing in GMod, I would recommend you read Peter Shirley's Ray Tracing in One Weekend which is linked above, and is the inspiration for this book.  

By the end of each section you should have a solid groundwork to either move into the next section with, or to develop onto yourself. And by the end of the book you'll have a pretty decent tracer.

While you could technically follow along without these, the book assumes you'll be using them:
* Garry's Mod
* VisTrace (subscribe to the Workshop addon and download the latest release binary from the GitHub)

You should also already be familiar with Lua (specifically GLua) and basic rendering terminology like shading.  

You'll be implementing the tracer as a simple GLua script run with `lua_openscript_cl` from the console, however you could follow along from Starfall or even write a fully fledged addon around the renderer.  

Drawing an Image
----------------

Before we get into the nitty gritty of light transport, we need to actually be able to draw pixels to our screen. While there are *many* ways to do this ranging from drawing to a physical screen in the world, to a VGUI frame you can use like a mini application, I've opted for the simplest and most efficient for this step (however you can ignore this and use whatever method you prefer if you're already familiar with rendering in GMod).  

To start with we need a script to work in, and an addon to place that script in. Create a new folder in your `garrysmod/addons` folder with any name you like, then create a subfolder called `lua` and a file in that folder called `vistracer.lua` (you can of course use whatever name you want, however the book assumes this is what you called it). You should now have the file `garrysmod/addons/youraddonname/lua/vistracer.lua`.  

Open the file in your text editor of choice (I recommend vscode with sumneko's Lua extension and the GLua annotations) and add the following

~~~ lua
print("VisTracing in One Weekend!")
~~~

![Console Output](./images/vistracing-in-one-weekend/console-print.png)

Launch GMod and start singleplayer (or join a multiplayer server with clientside Lua enabled), open console with the grave/backtick key, and enter `lua_openscript_cl vistracer.lua`. You should see `VisTracing in One Weekend!` appear in your console! If not then check that `sv_allowcslua` is set to `1`, and that GMod has been restarted since you created `vistracer.lua` (it only hotloads existing files).  

Now to draw something to the screen we need a render context, and in this case I've chosen the `HUDPaint` hook as a simple way to get pixels above everything except the menu. Remove the print we added and replace it with the hook

~~~ lua
hook.Add("HUDPaint", "VisTracer", function()

end)
~~~  

This wont do anything yet, but go ahead and run it just to check everything's working. We have a render context, but we need to actually draw something. For now lets just use a red rectangle

~~~ lua
hook.Add("HUDPaint", "VisTracer", function()
	~~~ lua highlight
	surface.SetDrawColor(255, 0, 0)
	surface.DrawRect(0, 0, 256, 256)
	~~~ lua
end)
~~~

![`surface.DrawRect`](./images/vistracing-in-one-weekend/surface-draw.png)

You may be thinking that this is how we'll render an entire image, however if you were to add a print to this hook you'd see that it's called every frame. You can imagine how laggy our game would get if we were ray tracing a scene every frame in Lua.

Instead we need a way to render a set of pixels only once, and save them for future frames. To do this we're going to use *render targets*, which are a special kind of texture we're able to draw to, and the pixels we draw will be saved indefinitely (quite literally in fact, GMod doesn't destroy render targets until the game closes).  

First of all we need to create a render target to use, in addition to a material to assign the render target to as a base texture in order to draw it to the screen later

~~~ lua
local rt = GetRenderTargetEx(
	"VisTracer",                     -- Name of the render target
	1, 1, RT_SIZE_FULL_FRAME_BUFFER, -- Resize to screen res automatically
	MATERIAL_RT_DEPTH_SEPARATE,      -- Create a dedicated depth/stencil buffer
	bit.bor(1, 256),                 -- Texture flags for point sampling and no mips
	0,                               -- No RT flags
	IMAGE_FORMAT_RGBA8888            -- RGB image format with 8 bits per channel
)

local rtMat = CreateMaterial("VisTracer", "UnlitGeneric", {
	["$basetexture"] = rt:GetName(),
	["$translucent"] = "1" -- Enables transparency on the material
})

...
~~~

Next we draw the render target to the screen

~~~ lua
...

hook.Add("HUDPaint", "VisTracer", function()
	~~~ lua delete
	surface.SetDrawColor(255, 0, 0)
	surface.DrawRect(0, 0, 256, 256)
	~~~ lua highlight
	render.SetMaterial(rtMat)
	render.DrawScreenQuad() -- Draws a quad to the entire screen
	~~~ lua
end)
~~~

If you run this with `lua_openscript_cl vistracer.lua` you should get a black screen (don't worry, use `lua_run_cl hook.Remove("HUDPaint", "VisTracer")` to get rid of the hook). This isn't exactly what we want, so lets try drawing some pixels.  

While we could draw to the render target immediately when we run our script, we're going to want to split the drawing over multiple frames for later (ray tracing single threaded in Lua is not fast). To do this we can ignore more complicated (and slower) methods of spreading our code over multiple frames, and just render one row per frame. We also need to define an x and y resolution to draw, which we'll place at the top of the file (this is where all of our parameters will go)

~~~ lua highlight
local RESX, RESY = 256, 256
~~~ lua

...


~~~ lua highlight
local y = 0
~~~ lua
hook.Add("HUDPaint", "VisTracer", function()
	~~~ lua highlight
	if y < RESY then
		render.PushRenderTarget(rt)

		for x = 0, RESX - 1 do
			render.SetViewPort(x, y, 1, 1)
			render.Clear(255, 0, 0, 255, true, true)
		end

		render.PopRenderTarget()
		y = y + 1
	end
	~~~ lua

	render.SetMaterial(rtMat)
	render.DrawScreenQuad()
end)
~~~

Running this should produce a 256x256 red rectangle just like the original `surface.DrawRect` method, except we now have control over the colour of individual pixels and we're only drawing each pixel once. You may also notice that we still have the same problem as before where the entire screen is black except for where we drew our rectangle.

To fix that we'll add a `setup` flag and clear the render target with 0 alpha before we start writing

~~~ lua
...

local y = 0

	~~~ lua highlight
local setup = true
	~~~ lua
hook.Add("HUDPaint", "VisTracer", function()
	if y < RESY then
		render.PushRenderTarget(rt)

		~~~ lua highlight
		if setup then
			render.Clear(0, 0, 0, 0, true, true)
			setup = false
		end
		~~~ lua

		for x = 0, RESX - 1 do
			render.SetViewPort(x, y, 1, 1)
			render.Clear(255, 0, 0, 255, true, true)
		end

		render.PopRenderTarget()
		y = y + 1
	end

	render.SetMaterial(rtMat)
	render.DrawScreenQuad()
end)
~~~

Et voila! You should now have a significantly slower to draw red rectangle! Not impressed? Well lets draw something slightly more interesting that we couldn't do with a simple `surface.DrawRect` call...

~~~ lua
		...

		for x = 0, RESX - 1
			render.SetViewPort(x, y, 1, 1)

			~~~ lua delete
			render.Clear(255, 0, 0, 255, true, true)
			~~~ lua

			~~~ lua highlight
			render.Clear(x / (RESX - 1) * 255, y / (RESY - 1) * 255, 0, 255, true, true)
			~~~ lua
		end

		...
~~~

Running our script now should produce a nice gradient from black to red on the x axis, and black to green on the y axis. You may also notice that the pixels are black in the *top left* of the rectangle, and not the bottom left as you might expect.

![Red on the X axis and green on the Y axis](./images/vistracing-in-one-weekend/xy-square.png)

Tracing a Ray
-------------

Before we dig into the meat of ray tracing, we need to know how to trace a ray, and to know that we need to know what a "ray" even is.

While it makes sense to think of a ray as a single "ray" of light (light is far more complicated than that in reality), it's actually the total of *all* light that follows a specific line defined by our ray.

Additionally we can define a ray as $\mathbf{x} = \mathbf{o} + t\mathbf{d}$, where $\mathbf{x}$ is the hit point of the ray, $\mathbf{o}$ is the origin, $\mathbf{d}$ is the direction, and $t$ is the *time* or distance along the ray.

Tracing a ray in this context is solving the above equation for the lowest positive value of $t$, which we do by testing every part of the scene geometry for intersections with the ray. We wont have to worry about tracing the ray ourselves, as VisTrace handles this for us, but it's good to know roughly what's going on under the hood.

To trace a ray with VisTrace, it needs to know the scene geometry we want to trace before we can actually trace with it, which we can do by building an *acceleration structure*. The specifics of ray tracing acceleration structures are well outside the scope of this book, but if you want to look into them then VisTrace uses a [bounding volume hierarchy](https://en.wikipedia.org/wiki/Bounding_volume_hierarchy).

Thankfully building an acceleration structure with modern versions of VisTrace is easy, we simply call a function passing in an array of entities we want to intersect with, along with a boolean to toggle intersections with the world (by default it's true). For now we'll just trace any entities whose class starts with `prop_` and disable world tracing. I've also added some comments to help keep our code clean

~~~ lua highlight
----------------
-- Parameters --
----------------
~~~ lua
local RESX, RESY = 256, 256


~~~ lua highlight
----------------
--    Init    --
----------------
local accel = vistrace.CreateAccel(ents.FindByClass("prop_*"), false)
~~~ lua

local rt = GetRenderTargetEx(
	"VisTracer",                     -- Name of the render target
	1, 1, RT_SIZE_FULL_FRAME_BUFFER, -- Resize to screen res automatically
	MATERIAL_RT_DEPTH_SEPARATE,      -- Create a dedicated depth/stencil buffer
	bit.bor(1, 256),                 -- Texture flags for point sampling and no mips
	0,                               -- No RT flags
	IMAGE_FORMAT_RGBA8888            -- RGB image format with 8 bits per channel
)

...
~~~

Now we have our scene geometry in an acceleration structure we can start tracing some rays. While we could put all of this in the render hook from the previous section, to help with readability we're going to create a new function above our hook called `TracePixel`, which will be called from the hook with the x and y coordinates of the current pixel and will return an RGB vector

~~~ lua
...


~~~ lua highlight
local function TracePixel(x, y)
	return Vector(x / (RESX - 1), y / (RESY - 1), 0)
end
~~~ lua

local y = 0
local setup = true
hook.Add("HUDPaint", "VisTracer", function()
	if y < RESY then
		render.PushRenderTarget(rt)
		if setup then
			render.Clear(0, 0, 0, 0, true, true)
			setup = false
		end

		for x = 0, RESX - 1 do
			~~~ lua highlight
			local rgb = TracePixel(x, y)
			~~~ lua

			render.SetViewPort(x, y, 1, 1)
			~~~ lua delete
			render.Clear(x / (RESX - 1) * 255, y / (RESY - 1) * 255, 0, 255, true, true)
			~~~ lua highlight
			render.Clear(rgb[1] * 255, rgb[2] * 255, rgb[3] * 255, 255, true, true)
			~~~ lua
		end

		render.PopRenderTarget()
		y = y + 1
	end

	render.SetMaterial(rtMat)
	render.DrawScreenQuad() -- Draws a quad to the entire screen
end)
~~~

This should produce the exact same image as the end of the last section, however now we can add as much code as we want to `TracePixel` without cluttering the render hook. Also if you're wondering why we're doing `* 255` on the final RGB vector, instead of using 0-255 colours in `TracePixel`, it's because when doing any kind of rendering having `grey * grey` produce 255 (after clamping) is really not helpful.

To trace our ray, we need to know the start position and the direction to trace in. We'll get into generating camera rays in a bit but for now we're going to do [orthographic projection](https://en.wikipedia.org/wiki/Orthographic_projection), meaning all of our rays point in the exact same direction and the origin changes. This has the effect of no matter how close or far away something is, it will always look the same in our final image.

We're also going to use the player camera's origin and angles for our rays, although you could use anything you want

~~~ lua highlight
local camPos, camAng = LocalPlayer():EyePos(), LocalPlayer():EyeAngles()
~~~ lua
local function TracePixel(x, y)
	~~~ lua highlight
	local origin = camPos + camAng:Right() * x / RESX * 100 + camAng:Up() * (1 - y / RESY) * 100
	local camDir = camAng:Forward()

	local result = accel:Traverse(origin, camDir)
	if result then
		return Vector(1, 1, 1)
	else
		return Vector(0, 0, 0)
	end
	~~~ lua delete
	return Vector(x / (RESX - 1), y / (RESY - 1), 0)
	~~~ lua
end
~~~

![Kleiner sitting on a crate](./images/vistracing-in-one-weekend/orthographic.png)

Because we're just adding onto the player camera's position the rays aren't centred, so you'll need to look down and to the left, but we're now tracing a scene!

Ray Tracing
===========

We have pixels being drawn to the screen, and we have rays being traced, now it's time to simulate light with ray tracing. I wont bore you with a bunch of theory right away, but I will give you an overview of how the ray tracing algorithm works.

We start by generating a ray from a pixel given our camera's properties as well as any additional properties that affect ray generation (like jittering for MSAA), we then trace this ray out into the scene to get a hit point. If we missed it's up to us how we want to colour that pixel, however if we hit an object we plug the information about the hit as well as our ray into the *rendering equation*, which will determine the colour of the hit point that we then assign to the pixel.

We'll be simulating three kinds of light interactions in our ray tracer:
* Perfect diffuse reflection - Light is scattered in roughly all directions from the surface, i.e. Lambertian reflection.
* Perfect specular reflection - Light is scattered entirely in the direction obtained by reflecting our view direction about the surface normal
* Perfect specular transmission - Light is scattered entirely in the direction obtained by refracting our view direction about the surface normal

Generating Camera Rays
----------------------

Before we start lighting our scene, we need to replace the orthographic projection we did earlier with a perspective camera, specifically a [pinhole camera](https://en.wikipedia.org/wiki/Pinhole_camera).

We could parameterise our camera with a field of view value, however I've chosen focal length and sensor height as this can be integrated into various physically based post processing steps and ray generation upgrades like depth of field.

Add these to our parameters section at the top of the file. I've chosen a full frame sensor height of 35mm and a focal length of 60mm fairly arbitrarily, so feel free to play around with them

~~~ lua
----------------
-- Parameters --
----------------
local RESX, RESY = 256, 256
~~~ lua highlight
local FOCAL_LENGTH = 60
local SENSOR_HEIGHT = 35
~~~

Next we'll cache a couple of values that we'll use when generating a ray that wont change over a trace. These values are derived from using a field of view to determine the vertical scale, and then simplifying the equation using focal length to FoV conversion equations

~~~ lua
----------------
--    Init    --
----------------
local accel = vistrace.CreateAccel(ents.FindByClass("prop_*"), false)


~~~ lua highlight
local camScaleVertical = 0.5 * SENSOR_HEIGHT / FOCAL_LENGTH
local camScaleHorizontal = RESX / RESY * camScaleVertical
~~~

If you want a more detailed explanation of these or the FoV equivalents then take a look at [Scratchapixel's raygen tutorial](https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-generating-camera-rays/generating-camera-rays).

Now lets change our old orthographic projection code to the pinhole camera model using our vertical and horizontal scale values. Before we can scale our values though we need to centre our pixel coordinate to the camera's origin, as well as converting it to a unit square coordinate.

To start with we'll offset our pixel by 0.5 so that our coordinate represents the centre of the pixel and not the corner, and then normalise it by dividing by the width and height of the image respectively

\begin{align}
cam_x &= \frac{pixel_x + 0.5}{res_x} \\
cam_y &= \frac{pixel_y + 0.5}{res_y}
\end{align}

Then we'll convert this 0-1 coordinate to the unit square coordinates of -1 to 1. Note that whether you subtract the normalised pixel from 1, or 1 from the pixel, depends on the handedness of your coordinate system

\begin{align}
cam_x &= 1 - 2 * \frac{pixel_x + 0.5}{res_x} \\
cam_y &= 1 - 2 * \frac{pixel_y + 0.5}{res_y}
\end{align}

Finally we'll apply our horizontal and vertical scale values

\begin{align}
cam_x &= (1 - 2 * \frac{pixel_x + 0.5}{res_x}) * scale_h \\
cam_y &= (1 - 2 * \frac{pixel_y + 0.5}{res_y}) * scale_v
\end{align}

This gives us a position in camera space, which we'll then normalise and rotate to give us a direction in world space.

Finally, lets add this in code

~~~ lua
local camPos, camAng = LocalPlayer():EyePos(), LocalPlayer():EyeAngles()
local function TracePixel(x, y)
	~~~ lua delete
	local origin = camPos + camAng:Right() * x / RESX * 100 + camAng:Up() * (1 - y / RESY) * 100
	local camDir = camAng:Forward()
	~~~ lua highlight
	local camX = (1 - 2 * (x + 0.5) / RESX) * camScaleHorizontal
	local camY = (1 - 2 * (y + 0.5) / RESY) * camScaleVertical

	local camDir = Vector(1, camX, camY)
	camDir:Rotate(camAng)
	camDir:Normalize()
	~~~ lua


	~~~ lua delete
	local result = accel:Traverse(origin, camDir)
	~~~ lua highlight
	local result = accel:Traverse(camPos, camDir)
	~~~ lua
	if result then
		return Vector(1, 1, 1)
	else
		return Vector(0, 0, 0)
	end
end
~~~

This should work just fine but lets replace our boring black and white view with one of the best features in VisTrace, automatic texturing

~~~ lua
	if result then
		~~~ lua delete
		return Vector(1, 1, 1)
		~~~ lua highlight
		return result:Albedo()
		~~~ lua
	else
		return Vector(0, 0, 0)
	end
~~~

![The fruits of our labour](./images/vistracing-in-one-weekend/pinhole-camera.png)

The Rendering Equation
----------------------

\begin{equation}
L_o(\mathbf{x}, \omega_o, \lambda, t) = L_e(\mathbf{x}, \omega_o, \lambda, t) + \int_{\Omega} f_s(\mathbf{x}, \omega_i, \omega_o, \lambda, t)L_i(\mathbf{x}, \omega_i, \lambda, t)(\omega_i \cdot \mathbf{n}) \,d\omega_i
\end{equation}

There it is, the rendering equation, the singular equation that underpins all modern renderers. You may be thinking you chose the wrong project to work on this week looking at that, but it's actually far simpler than it looks, and even simpler because most of it we will be ignoring in ray tracing.

To start with lets strip out the symbols we dont need, $\lambda$ is the wavelength of light, which we're abstracting away by using an RGB vector for everything, and $t$ is the current time (not time along the ray, but some time value for animation). This leaves us with the following

\begin{equation}
L_o(\mathbf{x}, \omega_o) = L_e(\mathbf{x}, \omega_o) + \int_{\Omega} f_s(\mathbf{x}, \omega_i, \omega_o)L_i(\mathbf{x}, \omega_i)(\omega_i \cdot \mathbf{n}) \,d\omega_i
\end{equation}

There's still that scary integral in there, but we wont actually be using that until path tracing later on. Instead we're only sampling a single direction at every hit point.

\begin{equation}
L_o(\mathbf{x}, \omega_o) = L_e(\mathbf{x}, \omega_o) + f_s(\mathbf{x}, \omega_i, \omega_o)L_i(\mathbf{x}, \omega_i)(\omega_i \cdot \mathbf{n})
\end{equation}

One more term we can remove is $L_e$, which is the emitted radiance at the hit point. As we wont be sampling emissives directly (well outside the scope of this book) and we wont be bouncing around the scene randomly (path tracing), the only effect we'd get from including this is emissive objects appearing bright when viewed by the camera directly, as well as in reflection and refraction, but they wouldn't light the scene.

\begin{equation}
L_o(\mathbf{x}, \omega_o) = f_s(\mathbf{x}, \omega_i, \omega_o)L_i(\mathbf{x}, \omega_i)(\omega_i \cdot \mathbf{n})
\end{equation}

Now we've cut the equation down to size, lets go over the terms

* $\mathbf{x}$ is the hit point of the ray
* $\omega_o$ is the direction pointing back along the ray ($-\mathbf{d}$ from the ray equation in [1.2](#introduction/tracingaray))
* $\omega_i$ is the direction of scattered light, which in ray tracing is just light samples, reflection, and refraction
* $\mathbf{n}$ is the normal of the surface we hit
* $L_o(\mathbf{x}, \omega_o)$ is the rendering function itself, which calculates the radiance in the outgoing direction $\omega_o$ at the point $\mathbf{x}$
* $f_s(\mathbf{x}, \omega_i, \omega_o)$ is the [bidirectional scattering distribution function](https://en.wikipedia.org/wiki/Bidirectional_scattering_distribution_function), which calculates the amount of light reflected/transmitted from the incoming direction $\omega_i$ in the outgoing direction $\omega_o$. You wont need to worry about the more complex forms of this function, as we'll only be simulating very basic light interaction.
* $L_i(\mathbf{x}, \omega_i)$ is the radiance coming from the incoming direction of light, which is actually the exact same function as $L_o$, except from the hit point and in the direction of incoming light instead of from the camera, making the rendering equation recursive
* $(\omega_i \cdot \mathbf{n})$ is the weakening factor of irradiance due to light smearing over a surface. This will be 1 for our perfect specular reflection and transmission (a detailed explanation of why can be found [here](https://stackoverflow.com/questions/22431912/path-tracing-why-is-there-no-cosine-term-when-calculating-perfect-mirror-reflec))

Armed with this simplified rendering equation, we can now move on to implementing lighting for diffuse surfaces.

Lighting
--------

Before we can light our scene, we need a source of light. There are many types of lights available to use and we can implement any that we want, but here's a few of the easiest

* Point lights are defined by a single point in space (hence the name) and are a good option for simple and versatile lights
* Directional/distance lights emulate the sun by being defined by a direction instead of a point. These are the simplest to implement however produce the least realistic looking lighting
* Area lights are a good alternative to emissives (in fact they're basically how emissives are sampled directly). While a rectangle is the most commonly used form of these, they can be any primitive shape or even a collection of primitives

There are also a few more complex light types

* Emissives are ordinary objects that emit light, and are the most realistic light source. Sampling these however is the hardest, especially when using emissive textures.
* Spot lights are effectively an extension of the point light to emit only in a cone extending from the light. These can also be given soft shadows at the edges, however as they're still an infinitely small point objects will cast hard shadows.
* HDRIs can be used to provide image based lighting. IBL provides both the most realistic lighting information for an environment, as well as being relatively easy to sample and produces minimal noise in the final render

We'll be implementing HDRIs as VisTrace provides functions that completely abstract the details of sampling away from us, and we can use a wide variety of HDRIs for different lighting conditions. This will have the downside of adding a small amount of noise to our ray tracer, but the results will be worth it.

First of all we need a HDRI to load, which I recommend getting from [Poly Haven](https://polyhaven.com/hdris). I'll be using [Drackenstein Quarry](https://polyhaven.com/a/drackenstein_quarry) by [Andreas Mischok](https://www.artstation.com/andreasmischok) throughout the book but you can grab whatever takes your fancy (everything is CC0 licensed!).

Note that while you can download both HDR and EXR formats, VisTrace only supports the HDR format.

Once you have some images you like, place them in `garrysmod/data/vistrace_hdris` so VisTrace can find them. All we have to do now is load one. We also need to create a *sampler* which we'll use in a second

~~~ lua
----------------
--    Init    --
----------------
local accel = vistrace.CreateAccel(ents.FindByClass("prop_*"), false)
~~~ lua highlight
local hdri = vistrace.LoadHDRI("drackenstein_quarry_4k")
local sampler = vistrace.CreateSampler()
~~~

Before we start using this for lighting, lets change our black background to the HDRI

~~~ lua
	local result = accel:Traverse(camPos, camDir)
	if result then
		return result:Albedo()
	else
		~~~ lua delete
		return Vector(0, 0, 0)
		~~~ lua highlight
		return hdri:GetPixel(camDir)
		~~~ lua
	end
~~~

If you look towards the sun you'll notice that everything turns into clown vomit. This is because our HDRIs are *hdr* images, meaning high dynamic range. As colours can be greater than 1 we need to convert them before drawing to our render target that stores 0-1.

We'll use something a little more complex to convert our 0-$\infty$ colours to 0-1 later on, however for now we'll just clamp before drawing to the RT

~~~ lua
		...

		for x = 0, RESX - 1 do
			local rgb = TracePixel(x, y)

			render.SetViewPort(x, y, 1, 1)
			~~~ lua delete
			render.Clear(rgb[1] * 255, rgb[2] * 255, rgb[3] * 255, 255, true, true)
			~~~ lua highlight
			render.Clear(
				math.Clamp(rgb[1] * 255, 0, 255),
				math.Clamp(rgb[2] * 255, 0, 255),
				math.Clamp(rgb[3] * 255, 0, 255),
				255, true, true
			)
			~~~ lua
		end

		...
~~~

Running our script now should render the HDRI whenever a camera ray misses the scene.

That was the easy part, we now need to use the HDRI sampling function along with our simplified rendering equation to determine the colour of the rays that hit.

\begin{equation}
L_o(\mathbf{x}, \omega_o) = f_s(\mathbf{x}, \omega_i, \omega_o)L_i(\mathbf{x}, \omega_i)(\omega_i \cdot \mathbf{n})
\end{equation}

Revisiting the equation we can see we need to calculate the value of $f_s$, $L_i$, and $(\omega_i \cdot \mathbf{n})$ in order to determine our outgoing colour. To start with we'll assume that $f_s$ is 1 and focus on the rest of the equation.

To calculate $L_i$ we can use the `HDRI:Sample()` function to pick a random value for $\omega_i$, we then trace a *shadow ray* out from our hit point in the sampled direction and if it misses the scene, we use the sampled colour. If the sample is invalid or the shadow ray hits an object, no lighting is calculated. We're also going to use the sampler we created earlier as the random number generator for the HDRI sampling function

~~~ lua
	local result = accel:Traverse(camPos, camDir)
	if result then
		~~~ lua delete
		return result:Albedo()
		~~~ lua highlight
		local colour = Vector()

		local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
		if envValid then
			local shadowRay = accel:Traverse(result:Pos(), envDir)
			if not shadowRay then
				colour = ...
			end
		end

		return colour
		~~~ lua
	else
		return hdri:GetPixel(camDir)
	end
~~~

We have our sampled $\omega_i$, as well as a shadow ray so we dont light the scene if the light is blocked. Now we need to compute $L_i$ and $(\omega_i \cdot \mathbf{n})$.

While it seems like we could just use `envCol` for $L_i$, this would heavily *bias* our renderer. The reason for this is because we're only sampling a single direction when we actually want to know all possible directions. This means that the amount of light we're saying is reaching the surface is far lower than it would be if we added together every possible sample direction.

To solve this and *unbias* our renderer, we can divide `envCol` by `envPdf` in order to boost the contribution of samples depending on their probability. We'll go into this in detail in the path tracing chapter, but for now just take it as read

~~~ lua
			if not shadowRay then
				~~~ lua highlight
				local Li = envCol / envPdf
				colour = Li
				~~~ lua
			end
~~~

That's $L_i$ done, next is $(\omega_i \cdot \mathbf{n})$ which is just the dot product between our sampled $\omega_i$ and surface normal $\mathbf{n}$

~~~ lua
			if not shadowRay then
				local Li = envCol / envPdf
				~~~ lua highlight
				colour = Li * envDir:Dot(result:Normal())
				~~~ lua
			end
~~~

If we run this now we should get some extremely noisy lighitng which we'll handle in a second, but we still need to add $f_s$.

In our case this will just be a bidirectional reflectance distribution function, specifically the Lambert BRDF which is about as simple as it gets.
\begin{equation}
f_{lambert} = \frac{albedo}{\pi}
\end{equation}

How this equation is derived is available [here](https://sakibsaikia.github.io/graphics/2019/09/10/Deriving-Lambertian-BRDF-From-First-Principles.html) which you can read if you feel like it, however you wont need to know how BRDFs etc are derived for this book.

Turning that into code is extremely simple

~~~ lua
			if not shadowRay then
				local Li = envCol / envPdf
				~~~ lua highlight
				local bsdf = result:Albedo() / math.pi
				colour = bsdf * li * envDir:Dot(result:Normal())
				~~~ lua
			end
~~~

Congratulations, you just implemented the rendering equation!

We still have a few issues to fix though, well one big issue spread all over our renders. *Noise*.

Our noise is actually a product of two things, the inherent randomness of sampling our HDRI, and something called *shadow acne*.

Shadow acne is an issue caused by floating point precision where the shadow ray starts too close to the surface and immediately intersects with it. Thankfully VisTrace provides a helper function to solve this

~~~ lua
	local result = accel:Traverse(camPos, camDir)
	if result then
		local colour = Vector()
		~~~ lua highlight
		local origin = vistrace.CalcRayOrigin(result:Pos(), result:GeometricNormal())
		~~~ lua

		local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
		if envValid then
			~~~ lua delete
			local shadowRay = accel:Traverse(result:Pos(), envDir)
			~~~ lua highlight
			local shadowRay = accel:Traverse(origin, envDir)
			~~~ lua
			if not shadowRay then
				local Li = envCol / envPdf
				local bsdf = result:Albedo() / math.pi
				colour = bsdf * Li * envDir:Dot(result:Normal())
			end
		end

		return colour
	else
		return hdri:GetPixel(camDir)
	end
~~~

![Woah that makes a difference!](./images/vistracing-in-one-weekend/shadow-acne.png)

The second source of noise, the random sampling, can't be solved with a single function call...

The only way we can reduce the noise of our random sampling (there are others but they're already being used by VisTrace in this instance) is by taking more than one sample.

We'll see this used across our entire renderer when path tracing, but for now we just need to take multiple samples from the HDRI. We can do this by averaging together samples.

This is actually a subset of the integral present in the rendering equation, and this method of approximating the integral by averaging random samples is [Monte Carlo integration](https://en.wikipedia.org/wiki/Monte_Carlo_integration), which we'll dig our teeth into when path tracing.

Lets start by adding a new parameter called `SAMPLES` which will be the number of samples to take at each hit

~~~ lua
----------------
-- Parameters --
----------------
local RESX, RESY = 512, 512
~~~ lua highlight
local SAMPLES = 8
~~~ lua

local FOCAL_LENGTH = 60
local SENSOR_HEIGHT = 35
~~~

Then wrap our hdri sampling in a for loop and divide the final colour by the number of samples

~~~ lua
	local result = accel:Traverse(camPos, camDir)
	if result then
		local colour = Vector()
		local origin = vistrace.CalcRayOrigin(result:Pos(), result:GeometricNormal())


		~~~ lua highlight
		for i = 1, SAMPLES do
		~~~ lua
			local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
			if envValid then
				local shadowRay = accel:Traverse(origin, envDir)
				if not shadowRay then
					local brdf = result:Albedo() / math.pi
					local Li = envCol / envPdf
					~~~ lua delete
					colour = brdf * Li * envDir:Dot(result:Normal())
					~~~ lua highlight
					colour = colour + brdf * Li * envDir:Dot(result:Normal())
					~~~ lua
				end
			end
		~~~ lua highlight
		end
		colour = colour / SAMPLES
		~~~ lua

		return colour
	else
		return hdri:GetPixel(camDir)
	end
~~~

One last improvement we can make is discarding invalid samples. The HDRI sampler shouldn't produce many but we don't want to let them contribute to the final image when it does

~~~ lua highlight
		local validSamples = SAMPLES
		~~~ lua
		for i = 1, SAMPLES do
			local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
			if envValid then
				local shadowRay = accel:Traverse(origin, envDir)
				if not shadowRay then
					local brdf = result:Albedo() / math.pi
					local Li = envCol / envPdf
					colour = colour + brdf * Li * envDir:Dot(result:Normal())
				end
			~~~ lua highlight
			else
				validSamples = validSamples - 1
			~~~ lua
			end
		end
		~~~ lua delete
		colour = colour / SAMPLES
		~~~ lua highlight
		colour = colour / validSamples
~~~

![With as few as 32 samples the lighting converges almost completely](./images/vistracing-in-one-weekend/hdri-sampling.png)

Reflection
----------

Our diffuse shading looks nice, but could be replicated by a decent rasteriser. To truly showcase the power of ray tracing lets do something that can't be done accurately with rasterising, *specular reflection*.

Specular reflection differs from diffuse reflection in that it's view dependent, it's also one of the two types of light interactions we'll fully explore in our ray tracer (diffuse interreflection is ignored as it's part of path tracing).

While specular reflection comes in many different forms, we're only going to implement perfect (aka delta) reflection for *conductive* surfaces. While we could implement a much wider variety of materials at this stage, this chapter is to prime you for path tracing and not to develop a complex ray tracer.

The details for why conductive and dielectric (non-conductive) materials interact with light differently is complex and not at all important for rendering. The only distinction it will make in our renderer is the type of Fresnel used (more on this later) and whether light not reflected specularly is transmitted or absorbed.

Before we start reflecting any rays we need to make some major modifications to our `TracePixel` function in order to handle multiple bounces. We could handle multiple bounces via recursion, however this is slow and can cause issues later on when you want access to information from the previous bounce.

To start we'll add a new parameter called `MAX_DEPTH` to prevent bouncing too many times

~~~ lua
----------------
-- Parameters --
----------------
local RESX, RESY = 512, 512
local SAMPLES = 32
~~~ lua highlight
local MAX_DEPTH = 8
~~~ lua

local FOCAL_LENGTH = 60
local SENSOR_HEIGHT = 35
~~~

Then we'll wrap our shading code in a loop and our diffuse shading code in an if statement, which for now will always be true as every surface is diffuse

~~~ lua
	local result = accel:Traverse(camPos, camDir)
	if result then
		local colour = Vector()


		~~~ lua highlight
		for depth = 1, MAX_DEPTH do
		~~~ lua
			local origin = vistrace.CalcRayOrigin(result:Pos(), result:GeometricNormal())


			~~~ lua highlight
			if true then
			~~~ lua
				local validSamples = SAMPLES
				for i = 1, SAMPLES do
					local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
					if envValid then
						local shadowRay = accel:Traverse(origin, envDir)
						if not shadowRay then
							local brdf = result:Albedo() / math.pi
							local Li = envCol / envPdf
							colour = colour + brdf * Li * envDir:Dot(result:Normal())
						end
					else
						validSamples = validSamples - 1
					end
				end

				colour = colour / validSamples
				~~~ lua highlight
				break
			end
		end
		~~~ lua

		return colour
	else
		return hdri:GetPixel(camDir)
	end
~~~

Now we need a way to determine when a surface is diffuse, and when it's specular.

We'll do this using a very rudementry method of checking if the material on an entity is `debug/env_cubemap_model`, which is the equivalent of a perfectly reflective surface in Source. This will be replaced with a more advanced system later on

~~~ lua
		for depth = 1, MAX_DEPTH do
			local origin = vistrace.CalcRayOrigin(result:Pos(), result:GeometricNormal())
			~~~ lua highlight
			local diffuse = true
			if result:Entity():IsValid() then
				diffuse = result:Entity():GetMaterial() ~= "debug/env_cubemap_model"
			end
			~~~ lua


			~~~ lua delete
			if true then
			~~~ lua highlight
			if diffuse then
			~~~ lua
				local validSamples = SAMPLES
				for i = 1, SAMPLES do
					local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
					if envValid then
						local shadowRay = accel:Traverse(origin, envDir)
						if not shadowRay then
							local brdf = result:Albedo() / math.pi
							local Li = envCol / envPdf
							colour = colour + brdf * Li * envDir:Dot(result:Normal())
						end
					else
						validSamples = validSamples - 1
					end
				end

				colour = colour / validSamples
				break
			~~~ lua highlight
			else
				colour = Vector(1, 0, 0)
				break
			~~~ lua
			end
		end
~~~

This should make all entities with the debug cubemap material appear red.  

The next step is to actually bounce off the surface to achieve reflection. Before adding a vector reflection function though, we'll bounce in the direction of the surface normal to make sure our loop works as we'd expect

~~~ lua
			else
				~~~ lua delete
				colour = Vector(1, 0, 0)
				break
				~~~ lua highlight
				local direction = result:Normal()
				result = accel:Traverse(origin, direction)

				if not result then
					colour = hdri:GetPixel(direction)
					break
				end
				~~~ lua
			end
~~~

![This generates a strange effect that almost looks like specular reflection, but is entirely view independent](./images/vistracing-in-one-weekend/proto-reflection.png)

We only have a couple things to add now to have conductive reflection, the first of which is an actual vector reflection function.  

As the following images from Scratchapixel show, the angle between the incident vector and the surface normal is equal to the angle between the reflected vector and the surface normal

![The angle of incidence and the angle of reflection are equal](https://www.scratchapixel.com/images/upload/shading-intro/shad-reflection.png)

Additionally, we can express the incident and reflected vectors using $A$ and $B$ like so

![The component vectors A and B of the reflection](https://www.scratchapixel.com/images/upload/shading-intro/shad-reflection2.png)

The equations for the incident vector $I$ and reflected vector $R$ are therefore

\begin{align}
I &= A + B \\
R &= A - B
\end{align}

Where $B$ is equal to

\begin{equation}
B = \cos\theta * N
\end{equation}

Substituting $B$ in the equations for $I$ and $R$ then gives us

\begin{align}
I &= A + \cos\theta * N \\
R &= A - \cos\theta * N
\end{align}

We then rearrange the equation for $I$ to solve for $A$

\begin{equation}
A = I - \cos\theta * N
\end{equation}

And finally we can substitute $A$ in the equation for $R$ and simplify, giving us the vector reflection equation

\begin{align}
R &= I - \cos\theta * N - \cos\theta * N \\
R &= I - 2\cos\theta * N
\end{align}

Now lets implement the above as a function in our tracer. Add a new function above `TracePixel` called `Reflect` which will take the surface normal and our incident vector

~~~ lua
...


~~~ lua highlight
local function Reflect(i, n)
	return i - 2 * i:Dot(n) * n
end
~~~ lua

local camPos, camAng = LocalPlayer():EyePos(), LocalPlayer():EyeAngles()
local function TracePixel(x, y)
	...
end
~~~

Then call this function to calculate a new direction to bounce in `TracePixel`. We'll also add a variable to store the direction that was traced to reach this point

~~~ lua
	...

	local result = accel:Traverse(camPos, camDir)
	if result then
		~~~ lua highlight
		local direction = camDir
		~~~ lua
		local colour = Vector()

		for depth = 1, MAX_DEPTH do
			local origin = vistrace.CalcRayOrigin(result:Pos(), result:GeometricNormal())
			local diffuse = true
			if result:Entity():IsValid() then
				diffuse = result:Entity():GetMaterial() ~= "debug/env_cubemap_model"
			end

			if diffuse then
				local validSamples = SAMPLES
				for i = 1, SAMPLES do
					local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
					if envValid then
						local shadowRay = accel:Traverse(origin, envDir)
						if not shadowRay then
							local brdf = result:Albedo() / math.pi
							local Li = envCol / envPdf
							colour = colour + brdf * Li * envDir:Dot(result:Normal())
						end
					else
						validSamples = validSamples - 1
					end
				end

				colour = colour / validSamples
				break
			else
				~~~ lua delete
				local direction = result:Normal()
				~~~ lua highlight
				direction = Reflect(direction, result:Normal())
				~~~ lua
				result = accel:Traverse(origin, direction)

				if not result then
					colour = hdri:GetPixel(direction)
					break
				end
			end
		end

		return colour
	else
		return hdri:GetPixel(camDir)
	end
~~~

Note that we've left `camDir` as a separate variable, this is redundant at the moment but will be useful when we start path tracing.

![Real specular reflection](./images/vistracing-in-one-weekend/delta-reflection.png)

We have one last step to complete in order to simulate conductors fully though, Fresnel.

The Fresnel equations describe the ratio between reflected and transmitted light, and are completely different for conductive and dielectric surfaces.

However the effect of Fresnel on conductors is extremely subtle, so instead we'll use an approximation common in both real time and offline renderers called [Schlick's approximation](https://en.wikipedia.org/wiki/Schlick%27s_approximation).

\begin{equation}
F(\theta) = F_0 + (1 - F_0)(1 - |\cos\theta|)^5
\end{equation}

Then we can simply use the colour of the surface hit as $F_0$ to achieve an approximate conductive material.

Add a new function called `FresnelSchlicks` after `Reflect`

~~~ lua
local function Reflect(i, n)
	return i - 2 * i:Dot(n) * n
end


~~~ lua highlight
local function FresnelSchlicks(i, n, f0)
	return f0 + (Vector(1, 1, 1) - f0) * math.pow(1 - math.abs(i:Dot(n)), 5)
end
~~~ lua

...
~~~

We now need to make another small change to our rendering code. At the moment we bounce around then set the colour to the first diffuse surface hit, however we want to colour our reflections.

To do this we use a throughput variable that's persistent throughout the ray's journey. This throughput holds the weight of the entire path a ray takes, including all interactions with surfaces along the way

~~~ lua
	...

	local result = accel:Traverse(camPos, camDir)
	if result then
		local direction = camDir
		local colour = Vector()
		~~~ lua highlight
		local throughput = Vector(1, 1, 1)
		~~~ lua

		...
~~~

Then simply multiply throughput by the Fresnel coefficient when we reflect, and multiply colour by the throughput when we terminate the path (diffuse surfaces and missed reflection rays)

~~~ lua
			...

			if diffuse then
				local validSamples = SAMPLES
				for i = 1, SAMPLES do
					local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
					if envValid then
						local shadowRay = accel:Traverse(origin, envDir)
						if not shadowRay then
							local brdf = result:Albedo() / math.pi
							local Li = envCol / envPdf
							colour = colour + brdf * Li * envDir:Dot(result:Normal())
						end
					else
						validSamples = validSamples - 1
					end
				end

				~~~ lua delete
				colour = colour / validSamples
				~~~ lua highlight
				colour = colour / validSamples * throughput
				~~~ lua
				break
			else
				direction = Reflect(direction, result:Normal())
				~~~ lua highlight
				local f0 = result:Entity():GetColor()
				throughput = throughput * FresnelSchlicks(
					direction, result:Normal(),
					Vector(f0.r / 255, f0.g / 255, f0.b / 255)
				)
				~~~ lua
				result = accel:Traverse(origin, direction)

				if not result then
					~~~ lua delete
					colour = hdri:GetPixel(direction)
					~~~ lua highlight
					colour = hdri:GetPixel(direction) * throughput
					~~~ lua
					break
				end
			end
~~~

We can't use `result:Albedo()` to get the entity's colour as the debug cubemap material has no base texture, meaning VisTrace would fall back to the missing texture.

![I love gold!](./images/vistracing-in-one-weekend/conductor.png)

Refraction
----------

Refraction, or specular transmission, is quite a different beast than specular reflection. In fact you need to both reflect and refract to produce a realistic refractive material with effects like total internal reflection.

We'll need to handle two separate ray paths, front and back surface interactions, a more complex Fresnel, and indices of refraction.

Lets start out the same way we started with reflection by adding a new clause to `TracePixel` for refractive objects. We'll classify all objects marked as specular with the cubemap that have an alpha value below 255 as refractive

~~~ lua
			else
				~~~ lua highlight
				local entColour = result:Entity():GetColor()

				if entColour.a == 255 then
					~~~ lua
					direction = Reflect(direction, result:Normal())
					~~~ lua delete
					local f0 = result:Entity():GetColor()
					~~~ lua
					throughput = throughput * FresnelSchlicks(
						direction, result:Normal(),
						~~~ lua delete
						Vector(f0.r / 255, f0.g / 255, f0.b / 255)
						~~~ lua highlight
						Vector(entColour.r / 255, entColour.g / 255, entColour.b / 255)
						~~~ lua
					)
					result = accel:Traverse(origin, direction)
				~~~ lua highlight
				else
					colour = Vector(1, 0, 0)
					break
				end
				~~~ lua

				if not result then
					colour = hdri:GetPixel(direction) * throughput
					break
				end
			end
~~~

We then need to compute a new origin based on whether we're entering or exiting the surface, and whether it's a front or back hit. We also need to flip the normal if we hit the back of the surface. Additionally lets "refract" by setting the direction to the negative of that upwards facing normal like we did for reflection

~~~ lua
			else
				local entColour = result:Entity():GetColor()

				if entColour.a == 255 then
					direction = Reflect(direction, result:Normal())
					throughput = throughput * FresnelSchlicks(
						direction, result:Normal(),
						Vector(entColour.r / 255, entColour.g / 255, entColour.b / 255)
					)
					result = accel:Traverse(origin, direction)
				else
					~~~ lua highlight
					local upNormal = result:Normal()

					if not result:FrontFacing() then
						upNormal = -upNormal
					end

					origin = not result:FrontFacing() and
						origin or
						vistrace.CalcRayOrigin(
							result:Pos(),
							-result:GeometricNormal()
						)

					direction = -upNormal
					result = accel:Traverse(origin, direction)
					~~~ lua delete
					colour = Vector(1, 0, 0)
					break
					~~~ lua
				end

				if not result then
					colour = hdri:GetPixel(direction) * throughput
					break
				end
			end
~~~

![Equally strange looking transmission to the prototype reflection earlier](./images/vistracing-in-one-weekend/proto-refraction.png)

Unfortunately the vector refraction function isn't quite as simple as reflection, however the method is the same. We'll construct our transmitted vector using $A$ and $B$ vectors in the plane of incidence as with reflection, except this time the angle between the surface normal and transmitted vector is defined by Snell's law

\begin{equation}
\frac{\sin\theta_I}{\sin{\theta_T}} = \frac{\eta_T}{\eta_I}
\end{equation}

Where $\theta_I$ and $\theta_T$ are the angles between each vector and the normal (inverse of the normal in the case of the transmitted vector), and $\eta_I$ and $\eta_T$ are the indices of refraction for the mediums that the incident and transmitted vectors reside in.

![Illustration of the plane of incidence with reflection and transmission](https://www.scratchapixel.com/images/upload/shading-intro/shad-refraction6.png)

We can then express the transmitted vector $T$ as the sum of vectors $A$ and $B$

\begin{align}
T &= A + B \\
A &= M\sin\theta_T \\
B &= -N\cos\theta_T
\end{align}

![The basis vectors illustrated on a unit circle](https://www.scratchapixel.com/images/upload/shading-intro/shad-refraction7.png)

$N$ is simply the surface normal pointing in the incident direction, and $M$ can be calculated by normalising the vector produced by adding the incident vector $I$ and the height of the indicent vector in the normal direction $C$

\begin{align}
M &= \frac{I + C}{\sin\theta_I} \\
C &= N\cos\theta_I
\end{align}

Then substituting everything in the final equation gives us

\begin{align}
T &= A + B \\
T &= M\sin\theta_T - N\cos\theta_T \\
T &= \frac{(I + C) \sin\theta_T}{\sin\theta_I} - N\cos\theta_T \\
T &= \frac{(I + N\cos\theta_I) \sin\theta_T}{\sin\theta_I} - N\cos\theta_T
\end{align}

Using Snell's law we can remove the unkown $\theta_T$ in the first half of the equation
\begin{align}
\frac{\sin\theta_I}{\sin{\theta_T}} &= \frac{\eta_T}{\eta_I} \\
T &= \frac{\eta_I}{\eta_T}(I + N\cos\theta_I) - N\cos\theta_T
\end{align}

For the second half of the equation, we can use the following trigonometric identity

\begin{align}
\cos^{2}\theta + \sin^{2}\theta &\equiv 1 \\
\cos\theta &\equiv \sqrt{1 - \sin^{2}\theta}
\end{align}

Using that identity we can remove the final unknown $\theta_T$ by substituting $\cos\theta_T$ with the trigonometric identity, replacing $\sin^{2}\theta_T$ with Snell's law. We'll also replace $\sin^{2}\theta_I$ with $(1 - \cos^{2}\theta_I)$ using the same identity in order to not use any slow trignometry functions in code

\begin{align}
\sin{\theta_T} &= \frac{\eta_I}{\eta_T}\sin\theta_I \\
T &= \frac{\eta_I}{\eta_T}(I + N\cos\theta_I) - N\cos\theta_T \\
T &= \frac{\eta_I}{\eta_T}(I + N\cos\theta_I) - N\sqrt{1 - \sin^{2}\theta_T} \\
T &= \frac{\eta_I}{\eta_T}(I + N\cos\theta_I) - N\sqrt{1 - \left( \frac{\eta_I}{\eta_T} \right)^{2}\sin^{2}\theta_I} \\
T &= \frac{\eta_I}{\eta_T}(I + N\cos\theta_I) - N\sqrt{1 - \left( \frac{\eta_I}{\eta_T} \right)^{2}(1 - \cos^{2}\theta_I)}
\end{align}

Finally, we can simplify this equation further, first by defining some coefficients

\begin{align}
\eta^{-1} &= \frac{\eta_I}{\eta_T} \\
c_1 &= \cos\theta_I = -(N \cdot I) \\
c_2 &= \sqrt{1 - \left( \frac{\eta_I}{\eta_T} \right)^{2}(1 - \cos^{2}\theta_I)} = \sqrt{1 - \eta^{-2}(1 - c_1^{2})}
\end{align}

And then substituting in the equation for $T$

\begin{align}
T &= \frac{\eta_I}{\eta_T}(I + N\cos\theta_I) - N\sqrt{1 - \left( \frac{\eta_I}{\eta_T} \right)^{2}(1 - \cos^{2}\theta_I)} \\
T &= \eta^{-1}(I + c_1N) - c_2N \\
T &= \eta^{-1} I + \eta^{-1} c_1N - c_2N \\
T &= \eta^{-1} I + (\eta^{-1} c_1 - c_2)N
\end{align}

Now to implement in code. We'll need to add a special case for when the term in the square root is below 0. This is total internal reflection

~~~ lua
...

local function Reflect(i, n)
	return i - 2 * i:Dot(n) * n
end


~~~ lua highlight
local function Refract(i, n, invEta)
	local c1 = -i:Dot(n)
	local c2sqr = 1 - invEta * invEta * (1 - c1 * c1)

	if c2sqr < 0 then -- Total internal reflection
		return Vector(0, 0, 0)
	end

	return invEta * i + (invEta * c1 - math.sqrt(c2sqr)) * n
end
~~~ lua

local function FresnelSchlicks(i, n, f0)
	return f0 + (Vector(1, 1, 1) - f0) * math.pow(1 - math.abs(i:Dot(n)), 5)
end

...
~~~

Then we can replace our prototype transmission with our new refraction function. I'm using the approximate IoR of air and glass here

~~~ lua
				else
					local upNormal = result:Normal()
					~~~ lua highlight
					local eta = 1.5 / 1
					~~~ lua

					if not result:FrontFacing() then
						upNormal = -upNormal
						~~~ lua highlight
						eta = 1 / eta
						~~~ lua
					end

					origin = not result:FrontFacing() and
						origin or
						vistrace.CalcRayOrigin(
							result:Pos(),
							-result:GeometricNormal()
						)


					~~~ lua delete
					direction = -upNormal
					~~~ lua highlight
					direction = Refract(direction, upNormal, 1 / eta)
					if direction == Vector(0, 0, 0) then
						colour = Vector(1, 0, 0)
						break
					end
					~~~ lua
					result = accel:Traverse(origin, direction)
				end
~~~

![This still looks wrong as it's missing reflection, but the hard part is done](./images/vistracing-in-one-weekend/delta-refraction.png)

We have a problem though, we need to trace both a reflection and refraction ray but our iterative algorithm only allows exploring a single path (although it's most likely possible, it would be difficult compared to a recursive algorithm).

Tracing both a reflection and refraction path has an additional flaw though, in a scene with many refractive objects close together, each ray will split in half again and again creating an exponentially increasing number of paths.

Additionally, when the Fresnel coefficient is either high or low, we'd be performing the same amount of sampling on diffuse surfaces visible in both reflection and refraction paths despite one having a far lower impact on the final image.

The solution to all of these problems is to stochastically sample either a reflection or refraction path using the Fresnel coefficient. Recall when we implemented conductors that Fresnel describes the amount of light reflected, meaning we can use it as the probability a ray is reflected.

A downside with this method is that to implement this sampling effectively into our rendering algorithm, we'll need to sample the entire path minus the camera ray again and again. This will cause our delta reflection only conductors to be far less efficient, however this method is by far the best for any other surface type including rough reflections and diffuse reflection when we start path tracing.

First of all we need to drastically modify our `TracePixel` function once again to sample the entire path instead of only diffuse direct lighting

~~~ lua
local camPos, camAng = LocalPlayer():EyePos(), LocalPlayer():EyeAngles()
local function TracePixel(x, y)
	local camX = (1 - 2 * (x + 0.5) / RESX) * camScaleHorizontal
	local camY = (1 - 2 * (y + 0.5) / RESY) * camScaleVertical

	local camDir = Vector(1, camX, camY)
	camDir:Rotate(camAng)
	camDir:Normalize()

	~~~ lua delete
	local result = accel:Traverse(camPos, camDir)
	if result then
	~~~ lua highlight
	local camRay = accel:Traverse(camPos, camDir)
	if camRay then
		~~~ lua delete
		local direction = camDir
		~~~ lua
		local colour = Vector()


		~~~ lua highlight
		local validSamples = SAMPLES
		for sample = 1, SAMPLES do
			local result = camRay
			local direction = camDir
			~~~ lua
			local throughput = Vector(1, 1, 1)

			for depth = 1, MAX_DEPTH do
				local origin = vistrace.CalcRayOrigin(result:Pos(), result:GeometricNormal())
				local diffuse = true
				if result:Entity():IsValid() then
					diffuse = result:Entity():GetMaterial() ~= "debug/env_cubemap_model"
				end

				if diffuse then
					~~~ lua delete
					local validSamples = SAMPLES
					for i = 1, SAMPLES do
					~~~ lua
					local envValid, envDir, envCol, envPdf = hdri:Sample(sampler)
					if envValid then
						local shadowRay = accel:Traverse(origin, envDir)
						if not shadowRay then
							local brdf = result:Albedo() / math.pi
							local Li = envCol / envPdf
							~~~ lua delete
							colour = colour + brdf * Li * envDir:Dot(result:Normal())
							~~~ lua highlight
							local integral = brdf * Li * envDir:Dot(result:Normal())
							colour = colour + integral * throughput
							~~~ lua
						end
					else
						validSamples = validSamples - 1
					end
					~~~ lua delete
					end

					colour = colour / validSamples * throughput
					~~~ lua
					break
				else
					local entColour = result:Entity():GetColor()

					if entColour.a == 255 then
						direction = Reflect(direction, result:Normal())
						throughput = throughput * FresnelSchlicks(
							direction, result:Normal(),
							Vector(entColour.r / 255, entColour.g / 255, entColour.b / 255)
						)
						result = accel:Traverse(origin, direction)
					else
						local upNormal = result:Normal()
						local eta = 1.5 / 1

						if not result:FrontFacing() then
							upNormal = -upNormal
							eta = 1 / eta
						end

						origin = not result:FrontFacing() and
							origin or
							vistrace.CalcRayOrigin(
								result:Pos(),
								-result:GeometricNormal()
							)

						direction = Refract(direction, upNormal, 1 / eta)
						if direction == Vector(0, 0, 0) then
							~~~ lua delete
							colour = Vector(1, 0, 0)
							~~~ lua highlight
							colour = colour + Vector(1, 0, 0)
							~~~ lua
							break
						end
						result = accel:Traverse(origin, direction)
					end

					if not result then
						~~~ lua delete
						colour = hdri:GetPixel(direction) * throughput
						~~~ lua highlight
						colour = colour + hdri:GetPixel(direction) * throughput
						~~~ lua
						break
					end
				end
			end
		~~~ lua highlight
		end
		~~~ lua


		~~~ lua delete
		return colour
		~~~ lua highlight
		return colour / validSamples
		~~~ lua
	else
		return hdri:GetPixel(camDir)
	end
end
~~~

That's quite a few changes, so double check each deletion and addition if anything isn't working after this step.

All going well you should have the exact same renders as before, however both conductors and our half implemented specular transmissive materials will render far slower.

Now we can stochastically sample reflection and refraction in our transmissive material. Lets test with a hardcoded 20% chance of reflection

~~~ lua
					else
						local upNormal = result:Normal()
						local eta = 1.5 / 1

						if not result:FrontFacing() then
							upNormal = -upNormal
							eta = 1 / eta
						end


						~~~ lua highlight
						local reflection = sampler:GetFloat() < 0.2
						~~~ lua delete
						origin = not result:FrontFacing() and
						~~~ lua highlight
						origin = reflection == result:FrontFacing() and
						~~~ lua
							origin or
							vistrace.CalcRayOrigin(
								result:Pos(),
								-result:GeometricNormal()
							)


						~~~ lua delete
						direction = Refract(direction, upNormal, 1 / eta)
						~~~ lua highlight
						direction = reflection and
							Reflect(direction, upNormal) or
							Refract(direction, upNormal, 1 / eta)
						~~~ lua

						if direction == Vector(0, 0, 0) then
							colour = colour + Vector(1, 0, 0)
							break
						end
						result = accel:Traverse(origin, direction)
					end
~~~

![That definitely looks a lot more like a real world material than before](./images/vistracing-in-one-weekend/proto-reflection-transmission.png)

Now while we could use the nice and simple Schlick's approximation here too, the effect of Fresnel on dielectrics is far more apparent, so we'll implement the full dielectric Fresnel.

The equations for each polarity are taken from [this blog post](https://seblagarde.wordpress.com/2013/04/29/memo-on-fresnel-equations/) by Sebastien Lagarde. We're entirely ignoring the polarisation of light so the final coefficient is just the average of the two

\begin{align}
r_\bot &= \frac{\cos\theta_I - \eta\sqrt{1 - \eta^{-2}(1 - \cos^{2}\theta)}}{\cos\theta_I + \eta\sqrt{1 - \eta^{-2}(1 - \cos^{2}\theta)}} \\
r_\| &= \frac{\sqrt{1 - \eta^{-2}(1 - \cos^{2}\theta)} - \eta\cos\theta_I}{\sqrt{1 - \eta^{-2}(1 - \cos^{2}\theta)} + \eta\cos\theta_I} \\
R &= \frac{r_\bot + r_\|}{2}
\end{align}

You may notice that a few of these terms are repeated so we'll save them to some temporary variables. We'll also use the same trigonometric identity trick we used in the refraction function in order to avoid calling `math.sin`

~~~ lua
...

local function FresnelSchlicks(i, n, f0)
	return f0 + (Vector(1, 1, 1) - f0) * math.pow(1 - math.abs(i:Dot(n)), 5)
end


~~~ lua highlight
local function FresnelDielectric(i, n, eta)
	local c1 = -i:Dot(n)
	local c2sqr = 1 - (1 - c1 * c1) / (eta * eta)

	if c2sqr < 0 then -- Total internal reflection
		return 1
	end

	local c2 = math.sqrt(c2sqr)
	local c3 = eta * c2
	local c4 = eta * c1

	local rs = (c1 - c3) / (c1 + c3)
	local rp = (c2 - c4) / (c2 + c4)

	return 0.5 * (rs * rs + rp * rp)
end
~~~ lua

...
~~~

We can then replace our hardcoded reflection probability with this function like so

~~~ lua
						...

						~~~ lua delete
						local reflection = sampler:GetFloat() < 0.2
						~~~ lua highlight
						local reflection = sampler:GetFloat() < FresnelDielectric(
							direction, upNormal,
							eta
						)
						~~~ lua
						origin = reflection == result:FrontFacing() and
							origin or
							vistrace.CalcRayOrigin(
								result:Pos(),
								-result:GeometricNormal()
							)

						...
~~~

You may be wondering why we're not adjusting the throughput here. The contribution of the reflection and refraction paths are $\text{Fresnel}$ and $1 - \text{Fresnel}$ respectively, however those are also the probability that each path was sampled. This is actually a taste of what we'll see a lot more of in path tracing, where we divide the contribution of a path by the probability that it was sampled.

As the probability is the same as the contribution of each path in this instance, dividing them by each other produces $1$, leaving the throughput unchanged.

This may not make intuitive sense if you're not already familiar with statistics, however I will explain it in more detail when we start path tracing. For now, admire your work.

![A display of all facets of a specular transmissive material](./images/vistracing-in-one-weekend/fresnel.png)

Post Processing
---------------

The last feature we'll add to our ray tracer is post processing. This is a good cooldown after the fairly maths heavy section on refraction.

At the moment we're rendering our raw HDR render data out to the screen using a clamp, however the proper way to convert HDR to a standard monitor's sRGB colour space is to perform tonemapping and gamma correction.

These are both post processing steps as they're applied after we render the scene. A few other examples are FXAA, upscaling, and denoising.

We could implement some of these with relative ease in Lua, however VisTrace provides a custom render target class that has various methods including ACES fitted tonemapping and saving to disk. In addition, VisTrace extensions can add more render target methods to provide extended functionality ([like denoising](https://github.com/yogwoggf/gmdenoiser)).

To start we'll create two new render targets, one to store the HDR render data and one to store the final sRGB output for saving to PNG

~~~ lua
----------------
--    Init    --
----------------
local accel = vistrace.CreateAccel(ents.FindByClass("prop_*"), false)
local hdri = vistrace.LoadHDRI("drackenstein_quarry_4k")
local sampler = vistrace.CreateSampler()


~~~ lua highlight
local hdr = vistrace.CreateRenderTarget(RESX, RESY, VisTraceRTFormat.RGBFFF)
local srgb = vistrace.CreateRenderTarget(RESX, RESY, VisTraceRTFormat.RGB888)
~~~ lua

...
~~~

Then we'll add another flag to determine when to perform post processing, and switch between rendering and post processing in the pixel draw loop depending on that state
~~~ lua
local y = 0
local setup = true
~~~ lua highlight
local postprocess = false
~~~ lua
hook.Add("HUDPaint", "VisTracer", function()
	if y < RESY then
		render.PushRenderTarget(rt)
		if setup then
			render.Clear(0, 0, 0, 0, true, true)
			setup = false
		end

		for x = 0, RESX - 1 do
			~~~ lua delete
			local rgb = TracePixel(x, y)
			~~~ lua highlight
			local rgb
			if postprocess then
				rgb = hdr:GetPixel(x, y)

				-- Perform custom per-pixel post processing

				srgb:SetPixel(x, y, rgb)
			else
				rgb = TracePixel(x, y)
				hdr:SetPixel(x, y, rgb)
			end
			~~~ lua

			render.SetViewPort(x, y, 1, 1)
			render.Clear(
				math.Clamp(rgb[1] * 255, 0, 255),
				math.Clamp(rgb[2] * 255, 0, 255),
				math.Clamp(rgb[3] * 255, 0, 255),
				255, true, true
			)
		end

		render.PopRenderTarget()
		y = y + 1


		~~~ lua highlight
		if y >= RESY then
			if postprocess then
				srgb:Save("render.png")
			else
				y = 0
				postprocess = true

				-- Call full image post processing methods
			end
		end
		~~~ lua
	end

	render.SetMaterial(rtMat)
	render.DrawScreenQuad() -- Draws a quad to the entire screen
end)
~~~

This renders the image and displays the raw data as a preview, then switches to post processing at the end copying every pixel to the `RGB888` render target for saving to PNG, before finally saving the sRGB RT to disk as `render.png`.

Now we can drop in both tonemapping and gamma correction with ease

~~~ lua
			local rgb
			if postprocess then
				rgb = hdr:GetPixel(x, y)

				-- Perform custom per-pixel post processing
				~~~ lua highlight
				local gamma = 1 / 2.2
				for i = 1, 3 do
					rgb[i] = math.pow(rgb[i], gamma)
				end
				~~~ lua

				srgb:SetPixel(x, y, rgb)
			else
				rgb = TracePixel(x, y)
				hdr:SetPixel(x, y, rgb)
			end
~~~

~~~ lua
		if y >= RESY then
			if postprocess then
				srgb:Save("render.png")
			else
				y = 0
				postprocess = true

				-- Call full image post processing methods
				~~~ lua highlight
				hdr:Tonemap()
				~~~ lua
			end
		end
~~~

![From oversaturated and blown out highlights to Blender render in a few lines of code](./images/vistracing-in-one-weekend/post-processing.png)

Conclusion
----------

223 lines later and we have a fairly complete ray tracer showcasing conductive reflection and specular reflection transmission, in addition to sampled diffuse direct lighting that could be expanded to point, distant, and area lights with ease.

At this point you should have a grasp on the core concepts of light transport, as well as being more comfortable with implementing mathematical equations in code. You may also want to re-read everything up to this point to review anything you might not have understood on the first pass.

You could continue to build on this base with various additional features, or you can move on to path tracing, which will explore light transport in far more detail, doing away with many of the abstractions we made when ray tracing.

You can also share any renders you make on the [VisTrace discussions show and tell page](https://github.com/Derpius/VisTrace/discussions/categories/show-and-tell), and if you want any to be featured on the VisTrace workshop or future branding then you can submit them via the [showcase issue template](https://github.com/Derpius/VisTrace/issues/new/choose) or as pull request to the branding branch.

If you submit renders to the showcase then please use the [provided watermark](https://github.com/Derpius/VisTrace/blob/branding/watermark.svg), or I can add one using your GitHub username if not present.

![Obligatory Cornell box render](./images/vistracing-in-one-weekend/ray-tracer.png)

Path Tracing
============

Revisiting the Rendering Equation
----------------------

\begin{equation}
L_o(\mathbf{x}, \omega_o, \lambda, t) = L_e(\mathbf{x}, \omega_o, \lambda, t) + \int_{\Omega} f_s(\mathbf{x}, \omega_i, \omega_o, \lambda, t)L_i(\mathbf{x}, \omega_i, \lambda, t)(\omega_i \cdot \mathbf{n}) \,d\omega_i
\end{equation}

Brute Force Path Tracing
------------------------

Importance Sampling
-------------------

Next Event Estimation
---------------------

Multiple Importance Sampling
----------------------------

Conclusion
----------

Shading
=======

What is a BSDF?
---------------

The VisTrace BSDF
-----------------------

Writing Your Own
----------------

The Microfacet Model
--------------------

Choosing F, D, and G
-------------------

Putting it All Together
-----------------------

Further Reading
===============

<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><link rel="stylesheet" href="./css/book.css?v=1"><script src="markdeep.min.js" charset="utf-8"></script><script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
